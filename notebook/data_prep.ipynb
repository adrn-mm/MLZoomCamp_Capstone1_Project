{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/customer_churn_train.csv')\n",
    "df['area_code'] = df['area_code'].str.split('_').str[2]\n",
    "\n",
    "df_predict = pd.read_csv('../data/customer_churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df.select_dtypes(['int64','float64'])\n",
    "df_category = df.select_dtypes(['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris sebelum memfilter outlier: 4250\n",
      "Number of rows after filtering outliers: 3515\n"
     ]
    }
   ],
   "source": [
    "print(f'Jumlah baris sebelum memfilter outlier: {len(df)}')\n",
    "\n",
    "filtered_entries = np.array([True] * len(df))\n",
    "for col in df_numerical.columns.tolist():\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low_limit = Q1 - (IQR * 1.5)\n",
    "    high_limit = Q3 + (IQR * 1.5)\n",
    "\n",
    "    filtered_entries = ((df[col] >= low_limit) & (df[col] <= high_limit)) & filtered_entries\n",
    "\n",
    "df = df[filtered_entries]\n",
    "\n",
    "print(f'Number of rows after filtering outliers: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns before feature encoding process: (3515, 20)\n",
      "Number of rows and columns after feature encodign process: (3515, 72)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows and columns before feature encoding process: {df.shape}')\n",
    "\n",
    "for cat in ['international_plan','voice_mail_plan','churn']:\n",
    "  df[cat] = df[cat].astype(str).map({\"no\":0,\"yes\":1})\n",
    "\n",
    "for cat in ['state','area_code']:\n",
    "  one_hot_enc = pd.get_dummies(df[cat], prefix=cat)\n",
    "  df = df.join(one_hot_enc)\n",
    "\n",
    "df = df.drop(['state','area_code'], axis=1)\n",
    "\n",
    "print(f'Number of rows and columns after feature encodign process: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for col in df_numerical.columns.tolist():\n",
    "  df[col] = MinMaxScaler().fit_transform(df[col].values.reshape(len(df),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/customer_churn_train_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
